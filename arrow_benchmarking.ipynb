{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03a45f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Dev Version ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "import trustyai\n",
    "\n",
    "import pyarrow.jvm as pvjm\n",
    "trustyai.init()\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from trustyai.explainers import SHAPExplainer, LimeExplainer, CounterfactualExplainer\n",
    "from trustyai.local.counterfactual import simple_prediction\n",
    "from trustyai.local.counterfactual import counterfactual_prediction\n",
    "from trustyai.model import feature, output, PredictionInput, PredictionOutput\n",
    "from trustyai.utils import TestUtils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from trustyai.model import Model, ArrowModel\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0ca27",
   "metadata": {},
   "source": [
    "# Set Global Feature Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495939ac",
   "metadata": {},
   "source": [
    "# Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db13534",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 10000\n",
    "weights = np.random.rand(fs)\n",
    "bg_arr = np.random.rand(100, fs)\n",
    "exp_arr = np.random.rand(2, fs)\n",
    "bg_pi   = [PredictionInput([feature(name='f{}'.format(i),value=x,dtype=\"number\") for i, x in enumerate(row)]) for row in bg_arr]\n",
    "exp_pi = [PredictionInput([feature(name='f{}'.format(i),value=x,dtype=\"number\") for i, x in enumerate(row)]) for row in exp_arr]\n",
    "bg_pd = pd.DataFrame(bg_arr, columns=['f{}' for i in range(fs)])\n",
    "exp_pd = pd.DataFrame(bg_arr, columns=['f{}' for i in range(fs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b7b8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric=True\n",
    "# two output models  for TrustyAI, TrustyAI-Arrow, and Official \n",
    "def model_function(inputs):\n",
    "    input_data = np.array([[feature.value.as_number() for feature in pi.features] for pi in inputs])\n",
    "    output_1 = np.dot(input_data, weights)\n",
    "    if not numeric:\n",
    "        output_2 = [str(x) for x in input_data[:,0]]\n",
    "        return [PredictionOutput([output(name=\"dot\", dtype='number', value=output_1[i]),output(name=\"str\", dtype='text', value=output_2[i])]) for i in range(len(output_1))]\n",
    "    else:\n",
    "        return [PredictionOutput([output(name=\"dot\", dtype='number', value=output_1[i]),output(name=\"dot2\", dtype='number', value=output_1[i])]) for i in range(len(output_1))]\n",
    "\n",
    "def model_function_arrow(inputs):\n",
    "    output1 = inputs.dot(weights)\n",
    "    if not numeric:\n",
    "        output2 = inputs['f0'].apply(str)\n",
    "        return pd.DataFrame({'dot':output1,'str':output2})\n",
    "    else:\n",
    "        return pd.DataFrame({'dot':output1,'dot2':output1})\n",
    "\n",
    "def model_function_pure_numpy(inputs):\n",
    "    output = np.dot(inputs, weights)    \n",
    "    return np.stack([output, output], 1)\n",
    "    \n",
    "# single output models for TrustyAI, TrustyAI-Arrow, and Official \n",
    "def model_function_one_out(inputs):\n",
    "    input_data = np.array([[feature.value.as_number() for feature in pi.features] for pi in inputs])\n",
    "    output_1 = np.dot(input_data, weights)\n",
    "    return [PredictionOutput([output(name=\"dot\", dtype='number', value=output_1[i])]) for i in range(len(output_1))]\n",
    "    \n",
    "def model_function_one_out_arrow(inputs):\n",
    "    return pd.DataFrame({'dot':inputs.dot(weights)})\n",
    "    \n",
    "def model_function_one_out_pure_numpy(inputs):\n",
    "    return np.dot(inputs, weights)\n",
    "    \n",
    "model = Model(model_function)\n",
    "amodel = ArrowModel(model_function_arrow)\n",
    "\n",
    "modelOneOut = Model(model_function_one_out)\n",
    "modelOneOutArrow = ArrowModel(model_function_one_out_arrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce0e19",
   "metadata": {},
   "source": [
    "# Lime Benchmarking\n",
    "Numeric vs Numeric/Text models, TrustyAI vs TrustyAI-Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864c80bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Numeric: True ===\n",
      "TrustyAI time: 2.6532397270202637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.arrow.memory.util.MemoryUtil (file:/home/rob/Documents/RedHat/kogito/kogito-apps/explainability/explainability-core/target/lib/arrow-memory-core-6.0.1.jar) to field java.nio.Buffer.address\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.arrow.memory.util.MemoryUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrow time: 1.175849199295044\n",
      "=== Numeric: False ===\n",
      "TrustyAI time: 2.0149922370910645\n",
      "Arrow time: 1.2841930389404297\n"
     ]
    }
   ],
   "source": [
    "numeric=True\n",
    "prediction_outputs = model.predictAsync(exp_pi).get()\n",
    "predictions = [simple_prediction(input_features=exp_pi[i].features, outputs=prediction_outputs[i].outputs) for i in range(1)]\n",
    "print(\"=== Numeric:\", numeric,\"===\")\n",
    "\n",
    "t_start = time.time()\n",
    "lime_explainer = LimeExplainer(normalise_weights=True, perturbations=2, samples=nsamples)\n",
    "saliency_map = lime_explainer.explain(predictions[0], model)\n",
    "print(\"TrustyAI time:\", time.time()-t_start)\n",
    "\n",
    "t_start = time.time()\n",
    "lime_explainer = LimeExplainer(normalise_weights=True, perturbations=2, samples=nsamples)\n",
    "saliency_map = lime_explainer.explainArrow(predictions[0], amodel)\n",
    "print(\"Arrow time:\",time.time()-t_start)\n",
    "\n",
    "numeric=False\n",
    "print(\"=== Numeric:\", numeric,\"===\")\n",
    "prediction_outputs = model.predictAsync(exp_pi).get()\n",
    "predictions = [simple_prediction(input_features=exp_pi[i].features, outputs=prediction_outputs[i].outputs) for i in range(1)]\n",
    "\n",
    "t_start = time.time()\n",
    "lime_explainer = LimeExplainer(normalise_weights=True, perturbations=2, samples=nsamples)\n",
    "saliency_map = lime_explainer.explain(predictions[0], model)\n",
    "print(\"TrustyAI time:\", time.time()-t_start)\n",
    "\n",
    "t_start = time.time()\n",
    "lime_explainer = LimeExplainer(normalise_weights=True, perturbations=2, samples=nsamples)\n",
    "saliency_map = lime_explainer.explainArrow(predictions[0], amodel)\n",
    "print(\"Arrow time:\",time.time()-t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f248c1d",
   "metadata": {},
   "source": [
    "## TrustyAI vs TrustyAI-Arrow vs Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b52c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrustyAI time: 1.6536273956298828\n",
      "Arrow time: 0.4255807399749756\n",
      "Official time: 7.399468898773193\n"
     ]
    }
   ],
   "source": [
    "prediction_outputs = modelOneOut.predictAsync(exp_pi).get()\n",
    "predictions = [simple_prediction(input_features=exp_pi[i].features, outputs=prediction_outputs[i].outputs) for i in range(1)]\n",
    "\n",
    "t_start = time.time()\n",
    "lime_explainer = LimeExplainer(normalise_weights=False, perturbations=2, penalise_sparse_balance=False, samples=nsamples)\n",
    "saliency_map = lime_explainer.explain(predictions[0], modelOneOut)\n",
    "print(\"TrustyAI time:\", time.time()-t_start)\n",
    "\n",
    "t_start = time.time()\n",
    "lime_explainer = LimeExplainer(normalise_weights=False, perturbations=2, penalise_sparse_balance=False, samples=nsamples)\n",
    "saliency_map = lime_explainer.explainArrow(predictions[0], modelOneOutArrow)\n",
    "print(\"Arrow time:\",time.time()-t_start)\n",
    "\n",
    "t_start = time.time()\n",
    "lime_exp = lime_tabular.LimeTabularExplainer(bg_arr, mode=\"regression\", feature_names=['f{}' for i in range(fs)])\n",
    "explanation = lime_exp.explain_instance(exp_arr[0], model_function_one_out_pure_numpy, num_samples=nsamples)\n",
    "print(\"Official time:\", time.time()-t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ed6c2",
   "metadata": {},
   "source": [
    "# SHAP\n",
    "TrustyAi vs TrustyAI-Arrow vs Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57b03ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrustyAI time: 129.9765191078186\n",
      "Arrow time: 22.521101474761963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4528b244b54976adee0f323824c2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official time: 2.232710599899292\n"
     ]
    }
   ],
   "source": [
    "numeric = True\n",
    "prediction_outputs = model.predictAsync(exp_pi).get()\n",
    "predictions = [simple_prediction(input_features=exp_pi[i].features, outputs=prediction_outputs[i].outputs) for i in range(1)]\n",
    "\n",
    "t_start = time.time()\n",
    "shap_explainer = SHAPExplainer(background=bg_pi, samples=nsamples)\n",
    "explanation = shap_explainer.explain(predictions[0], model)\n",
    "shap_values = np.array([[feature_importance.getScore() for feature_importance in saliency.getPerFeatureImportance()] for saliency in explanation.getSaliencies()])\n",
    "print(\"TrustyAI time:\", time.time()-t_start)\n",
    "\n",
    "t_start = time.time()\n",
    "shap_explainer = SHAPExplainer(background=bg_pi, samples=nsamples)\n",
    "explanation = shap_explainer.explainArrow(predictions[0], amodel)\n",
    "shap_values = np.array([[feature_importance.getScore() for feature_importance in saliency.getPerFeatureImportance()] for saliency in explanation.getSaliencies()])\n",
    "print(\"Arrow time:\", time.time()-t_start)\n",
    "\n",
    "if fs<20:\n",
    "    import shap\n",
    "    t_start = time.time()\n",
    "    ske = shap.KernelExplainer(model_function_pure_numpy, bg_arr)\n",
    "    ske.shap_values(exp_arr[:1], nsamples=nsamples)\n",
    "    print(\"Official time:\", time.time()-t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21d51f",
   "metadata": {},
   "source": [
    "# Counterfactual Benchmarking\n",
    "TrustyAi vs TrustyAI-Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "284d8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrustyAI Time: 3.049556255340576\n",
      "Arrow Time: 12.246750593185425\n"
     ]
    }
   ],
   "source": [
    "numeric = True\n",
    "explainer = CounterfactualExplainer(steps=nsamples)\n",
    "goal = [output(name=\"dot\", dtype=\"number\", value=0.0, score=1.0), output(name=\"dot2\", dtype=\"number\", value=0.0, score=1.0)]\n",
    "domains = [(-10.0, 10.0)] * fs\n",
    "\n",
    "prediction = counterfactual_prediction(\n",
    "        input_features=exp_pi[0].getFeatures(),\n",
    "        outputs=goal,\n",
    "        domains=domains\n",
    ")\n",
    "t_start = time.time()\n",
    "counterfactual_result = explainer.explain(prediction, model)\n",
    "print(\"TrustyAI Time:\",time.time()-t_start)\n",
    "\n",
    "t_start = time.time()\n",
    "counterfactual_result = explainer.explainArrow(prediction, amodel)\n",
    "print(\"Arrow Time:\", time.time()-t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce07f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
