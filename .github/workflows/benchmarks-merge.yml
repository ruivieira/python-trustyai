name: TrustyAI Python benchmarks

on:
  push:
    branches:
      - 'main'
  pull_request:

permissions:
  contents: write
  deployments: write
  pages: write
  pull-requests: write

jobs:
  benchmark:
    name: Run pytest-benchmark benchmark
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - uses: actions/setup-java@v2
        with:
          distribution: "adopt"
          java-version: "11"
          check-latest: true
      - uses: stCarolas/setup-maven@v4
        with:
          maven-version: 3.8.1
      - name: Build explainability-core
        uses: ./.github/actions/build-core
      - name: Build arrow-converter
        uses: ./.github/actions/build-arrow-converter
      - name: Install TrustyAI Python package
        run: |
          pip install -r requirements-dev.txt
          pip install . --force --no-binary :trustyai:
      - name: Run benchmark
        run: |
          pytest tests/benchmarks/benchmark.py --benchmark-json tests/benchmarks/results.json
      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: TrustyAI continuous benchmarks
          tool: 'pytest'
          output-file-path: tests/benchmarks/results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          gh-pages-branch: gh-pages
          alert-threshold: '200%'
          comment-on-alert: true
          comment-always: true
          fail-on-alert: false
          alert-comment-cc-users: '@ruivieira'